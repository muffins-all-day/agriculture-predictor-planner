{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1746709300511,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"SBCtDMzDK8cd","outputId":"642f12d8-dacc-4d10-80ed-7b276dc220c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Agriculture App/agriculture-predictor-planner\n"]}],"source":["%cd /content/drive/MyDrive/Agriculture App/agriculture-predictor-planner"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1746711765386,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"IvwXgUvsFsN-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import joblib\n","from xgboost import XGBRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, train_test_split\n","from xgboost.callback import EarlyStopping\n","from re import IGNORECASE\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1746709335899,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"Tr1q8ZrWLzCC"},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n"]},{"cell_type":"markdown","metadata":{"id":"jFJkCMeGKubK"},"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1911,"status":"ok","timestamp":1746709339539,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"2FTUAKDtK1CU"},"outputs":[],"source":["#Load the data\n","df = pd.read_csv(\"data/final/master_crop.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78,"status":"ok","timestamp":1746628068539,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"ImevN9KSLjKq","outputId":"cd800e4e-f713-441c-cb17-c0fae42e7bb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 415573 entries, 0 to 415572\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count   Dtype  \n","---  ------    --------------   -----  \n"," 0   district  415573 non-null  object \n"," 1   year      415573 non-null  int64  \n"," 2   yield     415573 non-null  float64\n"," 3   crop      415573 non-null  object \n"," 4   month     399891 non-null  float64\n"," 5   tmax      399891 non-null  float64\n"," 6   tmin      399891 non-null  float64\n"," 7   precip    399891 non-null  float64\n"," 8   wind      399891 non-null  float64\n","dtypes: float64(6), int64(1), object(2)\n","memory usage: 28.5+ MB\n","None\n"]}],"source":["print(df.info(verbose=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrwSItAxLbYg"},"outputs":[],"source":["print(df.head(20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1746544989428,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"hyqZc7kc3BPz","outputId":"dcff1826-19fd-44ac-a8a7-5d711e89ac83"},"outputs":[{"name":"stdout","output_type":"stream","text":["853.6796118652677\n"]}],"source":["print(df['yield'].mean())"]},{"cell_type":"markdown","metadata":{"id":"k_19LL8qOX23"},"source":["1. **Model training method #1 (XGB RMSE: 595.6751212599659,\n","XGB R¬≤: 0.617056832224721)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46904,"status":"ok","timestamp":1746627985142,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"Y-c2l7ZIMx3K","outputId":"e816e2d5-4ba3-4643-c789-cfc79694a811"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGB RMSE: 571.1065163177335\n","XGB R¬≤: 0.6479943513291873\n"]}],"source":["# 1. Define the features and target\n","X = df.drop(columns=\"yield\")\n","y = df[\"yield\"]\n","\n","# 2. Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","\n","# 3. Define preprocessor (one-hot for categories, scale numeric)\n","preprocessor = ColumnTransformer([\n","    (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"district\", \"crop\", \"month\"]),\n","    (\"num\", StandardScaler(), [\"tmax\", \"tmin\", \"precip\", \"wind\", \"year\"])])\n","\n","\n","# 4. Build pipeline with XGBRegressor\n","pipeline = Pipeline([\n","    (\"preproc\", preprocessor),\n","    (\"model\", XGBRegressor(\n","        n_estimators=200,\n","        learning_rate=0.1,\n","        max_depth=6,\n","        random_state=42,\n","        tree_method=\"hist\",\n","        enable_categorical=True\n","    ))\n","])\n","\n","\n","# 5. Fit & evaluate\n","pipeline.fit(X_train, y_train)\n","y_pred = pipeline.predict(X_test)\n","\n","mse = mean_squared_error(y_test, y_pred)    # returns MSE\n","rmse = np.sqrt(mse)                         # take square root for RMSE\n","print(\"XGB RMSE:\", rmse)\n","print(\"XGB R¬≤:\", r2_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"TonGXIZSO1tW"},"source":["2**. üéØüéØüéØüéØüéØModel training method #2(more accurate): (XGB RMSE: 315.43857550884024,\n","XGB R¬≤: 0.8926146573109333)**\n","\n","The jump from RMSE ‚âà 595 ‚Üí 315 and R¬≤ ‚âà 0.62 ‚Üí 0.89 comes almost entirely from letting XGBoost handle categorical features natively (instead of One-Hot) and from adding your Year column as a continuous predictor.\n","\n","*Native categorical support*\n","\n","When you convert District and Crop to pandas category dtype and run\n","\n","model = XGBRegressor(..., enable_categorical=True)\n","model.fit(X_train, y_train)\n","\n","XGBoost learns optimal splits on each category directly‚Äîno sparse, high-dimensional one-hot vectors. This usually gives a big boost in both speed and accuracy, especially with moderately high-cardinality features.\n","\n","*Year as a numeric trend feature*\n","\n","By keeping Year as a real-valued input (instead of dropping it or one-hot encoding it), the model can pick up on secular trends (e.g. gradual improvements in yields over time). That temporal signal often explains a large chunk of variance."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49048,"status":"ok","timestamp":1746710732144,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"i67MRyAIMKMP","outputId":"ac92b6ea-2b4f-4eb8-fbe6-743c9acad454"},"outputs":[{"output_type":"stream","name":"stdout","text":["XGB RMSE: 315.43857550884024\n","XGB R¬≤: 0.8926146573109333\n"]}],"source":["# 1. Define the features and target\n","X = df.drop(columns=\"yield\")\n","y = df[\"yield\"]\n","\n","# 2. Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","\n","# 3. Convert District/Crop into categories\n","for df in (X_train, X_test):\n","    df[\"district\"] = df[\"district\"].astype(\"category\")\n","    df[\"crop\"]     = df[\"crop\"].astype(\"category\")\n","\n","\n","# 4. Setup XGBRegressor\n","model = XGBRegressor(\n","    n_estimators=200,\n","    learning_rate=0.1,\n","    max_depth=6,\n","    random_state=42,\n","    tree_method=\"hist\",\n","    enable_categorical=True\n",")\n","\n","# Add early‚Äêstopping via callback\n","model.set_params(callbacks=[EarlyStopping(rounds=20, save_best=True)])\n","\n","# 5. Fit directly on the DataFrame with categories\n","model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_test, y_test)],\n","    verbose=False\n",")\n","\n","# 6. Evaluate\n","y_pred = model.predict(X_test)\n","\n","\n","mse = mean_squared_error(y_test, y_pred)    # returns MSE\n","rmse = np.sqrt(mse)                         # take square root for RMSE\n","print(\"XGB RMSE:\", rmse)\n","print(\"XGB R¬≤:\", r2_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500447,"status":"ok","timestamp":1746630324062,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"},"user_tz":-330},"id":"0RJAa_CMKNxM","outputId":"59f353dd-4be5-43cc-cdd9-c79a591e8579"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Best CV RMSE: 656.02\n","Test   RMSE: 647.6145260923869\n","Test   R¬≤:   0.5473645498032093\n","Best Hyperparameters: {'model__subsample': 0.8, 'model__reg_lambda': 5, 'model__reg_alpha': 0, 'model__n_estimators': 100, 'model__max_depth': 5, 'model__learning_rate': 0.1, 'model__gamma': 1, 'model__colsample_bytree': 0.8}\n"]}],"source":["# 1. Split features & target\n","X = df.drop(columns=\"yield\")\n","y = df[\"yield\"]\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# 2. Define preprocessor (one-hot for categories, scale numeric)\n","preprocessor = ColumnTransformer([\n","    (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"district\", \"crop\", \"month\"]),\n","    (\"num\", StandardScaler(), [\"tmax\", \"tmin\", \"precip\", \"wind\", \"year\"])\n","])\n","\n","# 3. Build pipeline with XGBRegressor (no categorical flag needed)\n","pipeline = Pipeline([\n","    (\"preproc\", preprocessor),\n","    (\"model\", XGBRegressor(\n","        tree_method=\"hist\",\n","        random_state=42\n","    ))\n","])\n","\n","param_dist = {\n","    \"model__n_estimators\": [50, 100],\n","    \"model__learning_rate\": [0.05, 0.1],\n","    \"model__max_depth\": [3, 5],\n","    \"model__subsample\": [0.8],\n","    \"model__colsample_bytree\": [0.8],\n","    \"model__gamma\": [0, 1],\n","    \"model__reg_alpha\": [0, 0.1],\n","    \"model__reg_lambda\": [1, 5],\n","}\n","\n","# 5. Setup and run RandomizedSearchCV\n","rs = RandomizedSearchCV(\n","    pipeline,\n","    param_distributions=param_dist,\n","    n_iter=10,\n","    scoring=\"neg_root_mean_squared_error\",\n","    cv=3,\n","    error_score=\"raise\",\n","    verbose=2,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","rs.fit(X_train, y_train)\n","\n","# 6. Evaluate on the hold-out test set\n","best = rs.best_estimator_\n","y_pred = best.predict(X_test)\n","\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","r2   = r2_score(y_test, y_pred)\n","print(f\"Best CV RMSE: {(-rs.best_score_):.2f}\")\n","print(\"Test   RMSE:\", rmse)\n","print(\"Test   R¬≤:  \", r2)\n","print(\"Best Hyperparameters:\", rs.best_params_)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ih8SrT8FSoWE","outputId":"72d85ddd-c6e9-41fa-92e2-6203a7627589"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 30 candidates, totalling 90 fits\n","Best CV RMSE: 421.04\n","Test   RMSE: 399.60420128048327\n","Test   R¬≤:   0.8276642046240366\n","Best Hyperparameters: {'model__subsample': 0.6, 'model__reg_lambda': 10, 'model__reg_alpha': 0, 'model__n_estimators': 300, 'model__max_depth': 9, 'model__learning_rate': 0.2, 'model__gamma': 1, 'model__colsample_bytree': 1.0}\n"]}],"source":["# 1. Split features & target\n","X = df.drop(columns=\"yield\")\n","y = df[\"yield\"]\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# 2. Define preprocessor (one-hot for categories, scale numeric)\n","preprocessor = ColumnTransformer([\n","    (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), [\"district\", \"crop\", \"month\"]),\n","    (\"num\", StandardScaler(), [\"tmax\", \"tmin\", \"precip\", \"wind\", \"year\"])\n","])\n","\n","# 3. Build pipeline with XGBRegressor (no categorical flag needed)\n","pipeline = Pipeline([\n","    (\"preproc\", preprocessor),\n","    (\"model\", XGBRegressor(\n","        tree_method=\"hist\",\n","        random_state=42\n","    ))\n","])\n","\n","param_dist = {\n","    \"model__n_estimators\":      [50, 100, 200, 300],\n","    \"model__learning_rate\":     [0.01, 0.05, 0.1, 0.2],\n","    \"model__max_depth\":         [3, 5, 7, 9],\n","    \"model__subsample\":         [0.6, 0.8, 1.0],\n","    \"model__colsample_bytree\":  [0.6, 0.8, 1.0],\n","    \"model__gamma\":             [0, 1, 5],\n","    \"model__reg_alpha\":         [0, 0.1, 1],\n","    \"model__reg_lambda\":        [1, 5, 10],\n","}\n","\n","# 5. Setup and run RandomizedSearchCV\n","rs = RandomizedSearchCV(\n","    pipeline,\n","    param_distributions=param_dist,\n","    n_iter=30,\n","    scoring=\"neg_root_mean_squared_error\",\n","    cv=3,\n","    error_score=\"raise\",\n","    verbose=2,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","rs.fit(X_train, y_train)\n","\n","# 6. Evaluate on the hold-out test set\n","best = rs.best_estimator_\n","y_pred = best.predict(X_test)\n","\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","r2   = r2_score(y_test, y_pred)\n","print(f\"Best CV RMSE: {(-rs.best_score_):.2f}\")\n","print(\"Test   RMSE:\", rmse)\n","print(\"Test   R¬≤:  \", r2)\n","print(\"Best Hyperparameters:\", rs.best_params_)\n"]},{"cell_type":"code","source":["def predict_top5_crops(model, X_train, district, month, tmax, tmin, precip, wind, year=2022):\n","    \"\"\"\n","    Predict top 5 crops to sow in a given district and month based on weather.\n","\n","    Parameters:\n","        model: Trained XGBRegressor\n","        X_train: Training DataFrame (to extract category mappings + column order)\n","        district (str): District name\n","        month (int): Sowing month (1‚Äì12)\n","        tmax (float): Max temperature\n","        tmin (float): Min temperature\n","        precip (float): Precipitation\n","        wind (float): Wind speed\n","        year (int): Year value (must be same type used during training)\n","\n","    Returns:\n","        DataFrame: Top 5 crops and their predicted yields\n","    \"\"\"\n","    import pandas as pd\n","\n","    # 1. Get the trained categories and feature column order\n","    crop_cats = X_train[\"crop\"].cat.categories\n","    district_cats = X_train[\"district\"].cat.categories\n","    feature_order = X_train.columns.tolist()\n","\n","    # 2. Build prediction DataFrame (one row per crop)\n","    all_crops = crop_cats.tolist()\n","    predict_df = pd.DataFrame([\n","        {\n","            \"district\": district,\n","            \"year\": year,\n","            \"crop\": crop,\n","            \"month\": month,\n","            \"tmax\": tmax,\n","            \"tmin\": tmin,\n","            \"precip\": precip,\n","            \"wind\": wind\n","        }\n","        for crop in all_crops\n","    ])\n","\n","    # 3. Convert to categorical using training mappings\n","    predict_df[\"district\"] = pd.Categorical(predict_df[\"district\"], categories=district_cats)\n","    predict_df[\"crop\"] = pd.Categorical(predict_df[\"crop\"], categories=crop_cats)\n","\n","    # 4. Reorder columns to match training\n","    predict_df = predict_df[feature_order]\n","\n","    # 5. Predict\n","    predict_df[\"predicted_yield\"] = model.predict(predict_df)\n","\n","    # 6. Return top 5 crops\n","    top5 = (\n","        predict_df\n","        .sort_values(\"predicted_yield\", ascending=False)\n","        .head(5)\n","        .reset_index(drop=True)\n","    )\n","\n","    return top5[[\"crop\", \"predicted_yield\"]]\n"],"metadata":{"id":"RWBJfGZcAreq","executionInfo":{"status":"ok","timestamp":1746711328767,"user_tz":-330,"elapsed":18,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["top5 = predict_top5_crops(\n","    model=model,\n","    X_train=X_train,\n","    district=\"Dehradun\",\n","    month=6,\n","    tmax=34.0,\n","    tmin=22.0,\n","    precip=200.0,\n","    wind=2.5,\n","    year=2022\n",")\n","\n","print(top5)\n"],"metadata":{"id":"6wJMUpfsE-Ng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","joblib.dump(model, \"models/xgb_crop_yield_model.pkl\")\n","\n","# Save the crop/district categories\n","joblib.dump(X_train[\"crop\"].cat.categories.tolist(), \"models/crop_categories.pkl\")\n","joblib.dump(X_train[\"district\"].cat.categories.tolist(), \"models/district_categories.pkl\")\n","joblib.dump(X_train.columns.tolist(), \"models/feature_order.pkl\")  # To preserve column order\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LN1tFyjInTB","executionInfo":{"status":"ok","timestamp":1746711876429,"user_tz":-330,"elapsed":78,"user":{"displayName":"Arunima Srivastava","userId":"02311867983960104766"}},"outputId":"a0fca0e3-f03c-427f-8e76-8adaf7243b9e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['models/feature_order.pkl']"]},"metadata":{},"execution_count":17}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1cozHXHmnNgBXqXr6jq7MI6kJXCuhOifj","authorship_tag":"ABX9TyM/lRRoL9JfDjLHUJ77DgWk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}